{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0f7ef7",
   "metadata": {},
   "source": [
    "# Notebook for training the image detection algorithm.\n",
    "\n",
    "# Start HACK 2024, University of St.Gallen - Team \"Last Minute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05effd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_dishes = [\n",
    "    \"pizza\",\n",
    "    \"hamburger\",\n",
    "    \"fried_rice\",\n",
    "    \"ice_cream\",\n",
    "    \"french_fries\",\n",
    "    \"chocolate_cake\",\n",
    "    \"tacos\",\n",
    "    \"lobster_roll_sandwich\",\n",
    "    \"lasagna\",\n",
    "    \"chicken_wings\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d9bd7",
   "metadata": {},
   "source": [
    "First, the script imports defaultdict from the collections module, two functions (copy and copytree) from the shutil module, and the os module. defaultdict is a dictionary subclass that calls a factory function to supply missing values. copy and copytree are used for copying files and directories respectively. The os module allows interacting with the operating system.\n",
    "\n",
    "The <b>`setup_training_data`</b> function is then defined. It takes four arguments - txtfile, source, destination, and food_list. The txtfile is a text file that lists the food images, source is the folder where the images are currently stored, destination is where you want the selected images (based on food_list) to be copied to, and food_list which is the list of specific food types you're interested in.\n",
    "\n",
    "The function has a defaultdict food_types for storing food types as keys and their corresponding images as values. It reads the txtfile line by line. Each line is assumed to have \"/\". The part before \"/\" is the food type, and the part after it is the image file name for that food type. If the food type is in the food_list, it's added to food_types along with its image file name.\n",
    "\n",
    "Finally, it loops over the keys in food_types (i.e., the types of food), and for each food type, it checks if a directory with the food type’s name exists in the destination folder. If not, it creates such a directory. Then, it copies each image file associated with that food type from the source to the destination folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239cc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from shutil import copy, copytree, rmtree\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_training_data(txtfile, source, destination, food_list=top_10_dishes):\n",
    "\n",
    "    food_types = defaultdict(list)\n",
    "    with open(txtfile, \"r\") as file:\n",
    "        lines = [line.strip() for line in file.readlines()]\n",
    "        for l in lines:\n",
    "            food_type = l.split(\"/\")\n",
    "            if food_type[0] in food_list:\n",
    "                food_types[food_type[0]].append(food_type[1] + \".jpg\")\n",
    "    \n",
    "    for food in food_types.keys():\n",
    "        print(\"  \" + food, end=\"  \")\n",
    "        if not os.path.exists(os.path.join(destination, food)):\n",
    "            os.makedirs(os.path.join(destination, food))\n",
    "        for n in food_types[food]:\n",
    "            copy(os.path.join(source, food, n), os.path.join(destination, food, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94905378",
   "metadata": {},
   "source": [
    "Creating the train and test folders for the 10 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00dcf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chicken_wings    chocolate_cake    french_fries    fried_rice    hamburger    ice_cream    lasagna    lobster_roll_sandwich    pizza    tacos    chicken_wings    chocolate_cake    french_fries    fried_rice    hamburger    ice_cream    lasagna    lobster_roll_sandwich    pizza    tacos  "
     ]
    }
   ],
   "source": [
    "setup_training_data('train.txt', 'images', 'train')\n",
    "setup_training_data('test.txt', 'images', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1341d12",
   "metadata": {},
   "source": [
    "## PreProcess the data (Keras: ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2245b86b",
   "metadata": {},
   "source": [
    "ImageDataGenerator can be employed for image preprocessing and resizing tasks in preparation for training. Apart from these basic functionalities, ImageDataGenerator is also capable of image augmentation. Image augmentation involves applying transformations like shifting, rotating, or brightness alteration to the existing images for the purpose of enhancing the diversity of the training data. Such augmentations allow the machine learning model to anticipate and adapt to various scenarios during deployment, and enhance its ability to accurately identify a particular food irrespective of its orientation or brightness levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e226d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pacos\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\pacos\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "C:\\Users\\pacos\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\pacos\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "data_gen = ImageDataGenerator(rotation_range=30, rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea46b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 10 classes.\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = (235, 235)\n",
    "\n",
    "train_gen = data_gen.flow_from_directory('train', target_size=image_size) # class_mode default categorical\n",
    "test_gen = data_gen.flow_from_directory('test', target_size=image_size) # default batch_size is 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122e6866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chicken_wings': 0, 'chocolate_cake': 1, 'french_fries': 2, 'fried_rice': 3, 'hamburger': 4, 'ice_cream': 5, 'lasagna': 6, 'lobster_roll_sandwich': 7, 'pizza': 8, 'tacos': 9}\n"
     ]
    }
   ],
   "source": [
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c955a",
   "metadata": {},
   "source": [
    "# Creating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eaf170",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks often leverage the foundations of a previously trained model for computer vision tasks. That is, they utilize a base with pre-trained weights.\n",
    "\n",
    "What we usually do is take a model that has already been trained on image data and append this as the base to an untrained model, or what we call the 'head'. The base model retains its weights, which enable it to extract key features from images. We don't have to train the base from scratch. Instead, we simply connect it to new Dense layers in the head, to train the model to categorize these features.\n",
    "\n",
    "To put it concisely:\n",
    "\n",
    "<b>Base</b> → This is used to distill features using a convolutional base.\n",
    "\n",
    "<b>Head</b> → This is used to determine the class of the image using a dense head.\n",
    "\n",
    "We experimented with various base models, with InceptionV3 providing the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e594695",
   "metadata": {},
   "source": [
    "## Using InceptionV3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316367c",
   "metadata": {},
   "source": [
    "First things first, import the InceptionV3 model from Keras. Then set the weights to the pre-trained imagenet weights and set the input shape to the width and height of the image. Finally, we got to make sure that we’re freezing the weights since we don’t want to have to retrain our base.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbaa636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "input_shape = (235, 235, 3) # 235, 235 stands for w and h. The 3 stands for the three channels for RGB\n",
    "inception_model = InceptionV3(weights=\"imagenet\", input_shape=input_shape, include_top=False)\n",
    "inception_model.trainable = False # freeze weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b12cb1",
   "metadata": {},
   "source": [
    "## Creating the head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2866e77",
   "metadata": {},
   "source": [
    "### Build a Dense Head\n",
    "\n",
    "To substantially minimize the volume of information fed into the Dense layers, a GlobalAveragePooling layer was incorporated. A 30% dropout layer was also added to help avert overfitting. This is done by \"dropping out\" certain neurons which ensures the model doesn't depend excessively on particular neurons. The last step is to conclude with a Dense layer that consists of units equivalent to the total number of distinct classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efaa1da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 6, 6, 2048)        21802784  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,934,570\n",
      "Trainable params: 131,786\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(inception_model)\n",
    "#model.add(Conv2D(32, 2, activation='relu')) # filters=32, kernel_size=(2,2)\n",
    "#model.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(64, activation=\"relu\")) # 64 units\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f72e45",
   "metadata": {},
   "source": [
    "### Compiling our model\n",
    "At this stage, we need to set the optimizer, loss function, and metrics for our model. We'll be utilizing Adam as our optimizer. Adam, which stands for Adaptive Moment Estimation, is a popular variant of the stochastic gradient descent algorithm and is widely considered to be a high-performing general optimizer.\n",
    "\n",
    "The role of the loss function is to measure the difference between the model's predictions and the true values. In our scenario, since we are dealing with multi-class classification, we would use categorical crossentropy as the loss function. This is contrasted with a regression problem, which would typically use a loss function such as mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd1532b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c90a3",
   "metadata": {},
   "source": [
    "### Define Callbacks\n",
    "\n",
    "Callbacks are specific functions executed during the model's training process. In our specific instance, we use an 'early stopping' callback, which will cease the model's training if it fails to display the minimum specified improvement (designated here as min_delta=0.001) within the given duration (which is 5 epochs in this case).\n",
    "\n",
    "The 'checkpoint' function serves as another form of callback. It enables us to save snapshot versions or 'checkpoints' of our model at regular intervals throughout training. This can be advantageous for continuing training from a specific point if needed, or for model versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92711cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "earlystopping = EarlyStopping(min_delta=0.001, patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(filepath='food_model.hdf5', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3a91b",
   "metadata": {},
   "source": [
    "### Fit our model to the data\n",
    "At last, we reach the point where we actually train our model. We fit our model to our training and validation data, and incorporate the callbacks defined earlier in the process.\n",
    "\n",
    "It's important to remember that due to the presence of the early stopping callback, it's more beneficial to set a larger number of epochs. This allows the model to stop its training when it no longer registers an improvement in accuracy, rather than stopping prematurely due to reaching the predefined number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868213e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen, validation_data=test_gen, epochs=30, verbose=1, callbacks=[checkpoint, earlystopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a4cb6",
   "metadata": {},
   "source": [
    "## Graph Accuracy and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77810f69",
   "metadata": {},
   "source": [
    "Convert “history” into a pandas DataFrame so that we can use the built in function to quickly plot the change in accuracy and loss over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:,['loss', 'val_loss']].plot()\n",
    "history_df.loc[:,['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535948fd",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca57d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_101_top_10.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
